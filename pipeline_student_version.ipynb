{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"pipeline_student_version.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"t6z7ncXirnv7","colab_type":"text"},"source":["# Building an ETL Pipeline\n","\n","As the second part of the predict for Gather, you will need to build a pipeline of functions in python which does the following:\n","\n","1. Function to connect to twitter and scrapes \"Eskom_SA\" tweets.\n","<br>\n","<br>\n","2. Cleans/Processes the tweets from the scraped tweets which will create a dataframe with two new columns using the following functions: <br>\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a) Hashtag Remover from Analyse Functions\n","<br>\n","<br>\n","3. Functions which connects to your SQL database and uploads the tweets into the table you store the tweets in the database."]},{"cell_type":"code","metadata":{"id":"jtYowqI_RiBL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":334},"outputId":"0e4cd7d3-9fb2-464f-e4aa-be627fb8dbce","executionInfo":{"status":"error","timestamp":1583913256888,"user_tz":-120,"elapsed":1069,"user":{"displayName":"Thulani Ncube","photoUrl":"","userId":"02955531584453762077"}}},"source":["# General:\n","import tweepy           # To consume Twitter's API\n","import pandas as pd     # To handle data\n","import numpy as np      # For numerical computation\n","import json\n","# For plotting and visualization:\n","from IPython.display import display\n","import pyodbc\n"],"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-370d640d0fac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# For plotting and visualization:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyodbc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyodbc'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"EykRIHe8ykYS","colab_type":"text"},"source":["# Consumer and Access details\n","\n","Fill in your Consumer and Access details you should have recieved when applying for a Twitter API. "]},{"cell_type":"code","metadata":{"id":"lquylmvOnFvt","colab_type":"code","colab":{}},"source":["# Consumer:\n","CONSUMER_KEY    =  # Consumer Key\n","CONSUMER_SECRET =  # Consumer Secret\n","\n","# Access:\n","ACCESS_TOKEN  =    # Access Token\n","ACCESS_SECRET =    # Access Secret"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"01RMZH30RiBU","colab_type":"code","colab":{}},"source":["# API's setup:\n","def twitter_setup():\n","    \"\"\"\n","    Utility function to setup the Twitter's API\n","    with access and consumer keys from Twitter.\n","    \"\"\"\n","\n","    # Authentication and access using keys:\n","    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n","    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n","\n","    # Return API with authentication:\n","    api = tweepy.API(auth, timeout=1000)\n","    return api"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I5nbkmC9vk8F","colab_type":"text"},"source":["# Function 1:\n","\n","Write a function which:\n","- Scrapes _\"Eskom_SA\"_ tweets from Twitter. \n","\n","Function Specifications:\n","- The function should return a dataframe with the scraped tweets with just the \"_Tweets_\" and \"_Date_\". \n","- Will take in the ```consumer key,  consumer secret code, access token``` and ```access secret code```.\n","\n","NOTE:\n","The dataframe should have the same column names as those in your SQL Database table where you store the tweets."]},{"cell_type":"code","metadata":{"id":"eF6Vnzl3RiBX","colab_type":"code","colab":{}},"source":["def twitter_df(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_SECRET ):\n","\n","    # Code Here\n","    \n","    return None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mkUQUNKzpUN2","colab_type":"text"},"source":["# Function 2: Removing hashtags and the municipalities\n","\n","Write a function which:\n","- Uses the function you wrote in the Analyse section to extract the hashtags and municipalities into it's own column in a new data frame. \n","\n","Function Specifications:\n","- The function should take in the pandas dataframe you created in Function 1 and return a new pandas dataframe. "]},{"cell_type":"code","metadata":{"id":"o12Z44mZRiBb","colab_type":"code","colab":{}},"source":["twitter_df(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_SECRET)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UOuThS2kRiBf","colab_type":"code","colab":{}},"source":["def extract_municipality_hashtags(df):\n","    \n","    ### Code Here\n","    \n","    return None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L9bXQ_k8xOjV","colab_type":"text"},"source":["# Function 3: Updating SQL Database with pyODBC\n","\n","Write a function which:\n","- Connects and updates your SQL database. \n","\n","Function Specifications:\n","- The function should take in a pandas dataframe created in Function 2. \n","- Connect to your SQL database.\n","- Update the table you store your tweets in.\n","- Not return any output."]},{"cell_type":"code","metadata":{"id":"yqdiXb5JRiBo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rb4iWqFVXWO2","colab_type":"code","colab":{}},"source":["def pyodbc_twitter(connection, df, twitter_table):\n","  \"\"\" Connects to a SQL database and updates the twitter table on the database with tweets from a give dataframe\n","        \n","  Parameters:\n","      connection(object): The object that contains authentication and connection details to the SQL Database\n","      df(dataframe): Pandas dataframe that contains tweets to be appended to the SQL database\n","      twitter_table(object): Table object that will be updated with tweets from the dataframe\n","        \n","  Returns:\n","      None: Does not return any output\n","  \"\"\"\n","  conn = connection\n","  c = conn.cursor()\n","\n","  c.execute(twitter_table)\n","  conn.commit()\n","\n","  df.to_sql('twitter_table', conn, if_exists='replace', index = False)\n","  print('Database Updated Successfully')\n","  return None"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUcrdqu4hXBX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"b810a2d5-51bd-47f9-a65f-2bf730e82657","executionInfo":{"status":"error","timestamp":1583913248804,"user_tz":-120,"elapsed":701,"user":{"displayName":"Thulani Ncube","photoUrl":"","userId":"02955531584453762077"}}},"source":["pyodbc_twitter(connection = pyodbc.connect(driver='{SQL Server}',\n","                      host='EDSA-HC9M9S2\\SQLEXPRESS',\n","                      database='gather_eskom',\n","                      trusted_connection='true',\n","                      user='sa'),\n","    df = extract_municipality_hashtags(twitter_df(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_SECRET)),\n","    twitter_table = 'CREATE TABLE twitter_table (Tweets text, Date text, municipality text, hashtags text)')"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c819f4a8da00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pyodbc_twitter(connection = pyodbc.connect(driver='{SQL Server}',\n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'EDSA-HC9M9S2\\SQLEXPRESS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mdatabase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gather_eskom'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mtrusted_connection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       user='sa'),\n","\u001b[0;31mNameError\u001b[0m: name 'pyodbc' is not defined"]}]},{"cell_type":"code","metadata":{"id":"1IpUC3qpliTX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}